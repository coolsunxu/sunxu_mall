# RocketMQ 消费延迟（分钟级）原因总结与业界通用解决方案

> 适用场景：生产端发送成功、Broker 已入库，但应用侧 `onMessage` 触发存在**间歇性分钟级延迟**。
>
> 本文基于本次项目排障过程沉淀，供后续复用。

## 1. 问题现象

- 生产端日志显示发送成功（`SEND_OK`），且 Broker `storeTimestamp` 与发送时间一致。
- 消费端 `onMessage` 偶发在 **2～5 分钟**后才触发。
- 消息 **非延迟消息**、且 **非重试消息**（`delayTimeLevel=0`、`reconsumeTimes=0`）。

## 2. 根因结论（本次排障定位结果）

### 2.1 根因

**同一个 `consumerGroup` 存在多个在线实例（connections > 1）**，导致队列分配/再均衡（rebalance）抖动或队列被其他实例占用。

当消息落在当前实例暂未分配到的队列上时，就会表现为“消息已入库，但本实例过几分钟才消费到”。

### 2.2 为什么是这个原因

本次排障中对 consumerGroup 连接数的探测结果显示：

- **同一消费组连接数稳定为 2**（`connections=2`），说明该组被至少两个进程/实例同时消费。
- 同时 JVM 心跳与 GC 指标平稳，排除“进程长时间停顿（如 Full GC/CPU 饥饿）”导致客户端无法拉取的可能。

因此，延迟更符合 RocketMQ 的 **队列分配与 rebalance 行为**，而不是业务侧阻塞或 JVM 卡顿。

## 3. 业界通用解决方案（建议按优先级落地）

### 3.1 consumerGroup 隔离（最常用、最有效）

**原则：一个业务消费逻辑（topic + tag + 处理语义）对应一个稳定且唯一的 consumerGroup。**

- **不要把 `rocketmq.consumer.group` 当作所有消费者的“通用默认值”**，否则新增消费者或本地多实例极易互相抢队列。
- **本地/测试环境**：
  - 建议 consumerGroup 带上环境/端口/实例标识，避免同机多进程互抢。
  - 典型做法：`${server.port}`、`${spring.profiles.active}`、`${HOSTNAME}` 等。
- **生产环境**：
  - 同一业务的多个实例应共享同一个 group 做负载均衡，但必须保证它们：
    - 订阅一致（topic/tag/selector 一致）
    - 处理逻辑一致
    - 幂等一致

### 3.2 订阅一致性与幂等（必须项）

- **订阅一致性**：
  - 同组内订阅必须一致；否则 rebalance 时会出现不可预期行为（例如某些队列/消息长期无法被某实例正确处理）。
- **幂等处理**：
  - 使用业务 Key（如订单号/任务 bizKey）做去重或状态机推进。
  - 允许重复投递、允许 rebalance 导致的重复消费。

### 3.3 监控与告警（生产必备）

建议至少监控这些指标：

- **consumerConnections**：消费组连接数是否异常飙升/下降
- **diffTotal / maxDiff**：堆积是否持续增长
- **consume RT / TPS**：消费耗时与吞吐
- **重试率**：异常是否导致重试风暴
- **rebalance 频率**：是否存在频繁上下线/订阅变动

当出现分钟级延迟时，优先排查：

- 是否有“僵尸进程/残留实例”仍在同组消费
- 是否有其他服务误用同一 consumerGroup
- 是否灰度/多环境共享了同一个 group

### 3.4 并发与隔离（防止另一类“真堆积”延迟）

另一类常见延迟是“业务侧慢/阻塞导致真堆积”，建议：

- 消费线程池与业务线程池隔离（避免消费线程被 IO/导出等慢任务拖死）
- 合理配置 `consumeThreadMin/Max` 与批量拉取参数
- 对慢任务做降级/限流/异步化

## 4. 本项目落地做法（已验证有效）

- 为任务执行消费者增加独立配置：
  - `app.mq.rocket.task-consumer-group`
- 本地默认按端口区分，避免同机多实例互抢：
  - `mall-rocket-consumer-group-task-${server.port}`

> 备注：生产环境通常覆盖为固定值（不带端口），以便同一业务服务集群共享 group 实现负载均衡。

